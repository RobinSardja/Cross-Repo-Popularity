{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating Cross-Repo Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unorganized Notes\n",
    "- Main Dataset https://www.kaggle.com/datasets/johntukey/github-dataset\n",
    "- Cross-Repo Paper https://ieeexplore.ieee.org/document/8947641"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load JSON dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste file directory below\n",
    "path = \"dataset.json\"\n",
    "\n",
    "df = pd.read_json( path, lines = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Add commit list to repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a list of repos with their commits\n",
    "def addCommitListToRepos(df):\n",
    "\n",
    "    # main dataset only keeps username, user id, number of commits, and commit list\n",
    "    df = df[ [ \"login\", \"id\", \"commits\", \"commit_list\" ] ]\n",
    "\n",
    "    # copy of the dataset used only for iterating through each user's commit lists\n",
    "    commitLists = df.copy()\n",
    "\n",
    "    # only keep commit list\n",
    "    commitLists = commitLists[ \"commit_list\" ]\n",
    "\n",
    "    # add commits to repos\n",
    "    reposWithCommits = {}\n",
    "    for currList in commitLists:\n",
    "        for commit in currList:\n",
    "            if commit[ \"repo_id\" ] not in reposWithCommits:\n",
    "                reposWithCommits[ commit[ \"repo_id\" ] ] = []\n",
    "            reposWithCommits[ commit[ \"repo_id\" ] ].append( commit )\n",
    "\n",
    "    # return repos with commits for further use in this notebook\n",
    "    return reposWithCommits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printReposWithCommits(reposWithCommits, max_repos=5, max_commits_per_repo=10):\n",
    "    # Create a shallow copy of the dictionary to avoid mutating the original data\n",
    "    limitedReposWithCommits = dict(list(reposWithCommits.items())[:max_repos])\n",
    "    \n",
    "    # Limit the number of commits per repository\n",
    "    for repo_id, commits in limitedReposWithCommits.items():\n",
    "        limitedReposWithCommits[repo_id] = commits[:max_commits_per_repo]\n",
    "\n",
    "    # Convert the limited dictionary to a JSON string with indentation for readability\n",
    "    reposWithCommitsJson = json.dumps(limitedReposWithCommits, indent=4)\n",
    "    print(reposWithCommitsJson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initialize a dictionary with keys of repo IDs and values of a list of commits to that repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reposWithCommits = addCommitListToRepos(df)\n",
    "\n",
    "# Call the function with your data, specifying how many repos and commits per repo to print\n",
    "printReposWithCommits(reposWithCommits, max_repos=5, max_commits_per_repo=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4b. Test for proper intialization of reposWithCommits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming reposWithCommits is a dictionary where keys are repo IDs and values are lists of commits\n",
    "\n",
    "# Calculate the total number of repos\n",
    "total_repos = len(reposWithCommits.keys())\n",
    "\n",
    "# Calculate the total number of commits\n",
    "numCommits = sum(len(commitList) for commitList in reposWithCommits.values())\n",
    "\n",
    "# Data for specific repo IDs\n",
    "repo_ids = [121300003, 88377551, 131508193, 132465788, 132464776]\n",
    "repos_data = {repo_id: reposWithCommits[repo_id] for repo_id in repo_ids if repo_id in reposWithCommits}\n",
    "\n",
    "# Structuring the data\n",
    "data_to_print = {\n",
    "    \"Total number of repos\": total_repos,\n",
    "    \"Total number of commits\": numCommits,\n",
    "    \"repos\": repos_data\n",
    "}\n",
    "\n",
    "# Pretty printing the data as JSON\n",
    "print(json.dumps(data_to_print, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to manually create two features:\n",
    "* Number of commits - commit count for a repository\n",
    "* Commit List - commit objects including commit timestamp & relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the structure into a list of dictionaries for DataFrame creation\n",
    "commit_details = []\n",
    "for repo_id, commits in reposWithCommits.items():\n",
    "    for commit in commits:\n",
    "        commit_details.append(commit)\n",
    "\n",
    "# Create the initial DataFrame\n",
    "df_commits = pd.DataFrame(commit_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'repo_id' to aggregate commits\n",
    "repo_summary = df_commits.groupby('repo_id').agg({\n",
    "    'repo_owner_id': 'first',  # Assuming repo_owner_id is constant per repo\n",
    "    'repo_description': 'first',  # Assuming repo_description is constant per repo\n",
    "    'repo_name': 'first',  # Assuming repo_name is constant per repo\n",
    "    'commit_at': lambda x: list(x),\n",
    "    'committer_id': lambda x: list(x),\n",
    "    'message': lambda x: list(x),\n",
    "    'generate_at': lambda x: list(x),\n",
    "    'author_id': lambda x: list(x)\n",
    "}).reset_index()\n",
    "\n",
    "# Create the 'commit_list' column by combining columns into dictionaries\n",
    "repo_summary['commit_list'] = repo_summary.apply(lambda row: [\n",
    "    {\n",
    "        'commit_at': commit_at,\n",
    "        'committer_id': committer_id,\n",
    "        'message': message,\n",
    "        'generate_at': generate_at,\n",
    "        'author_id': author_id\n",
    "    }\n",
    "    for commit_at, committer_id, message, generate_at, author_id in zip(\n",
    "        row['commit_at'], row['committer_id'], row['message'], row['generate_at'], row['author_id']\n",
    "    )\n",
    "], axis=1)\n",
    "\n",
    "# Calculate 'commit_count' for each repository\n",
    "repo_summary['commit_count'] = repo_summary['commit_list'].apply(len)\n",
    "\n",
    "# Drop individual commit columns as they are now aggregated into 'commit_list'\n",
    "repo_summary.drop(columns=['commit_at', 'committer_id', 'message', 'generate_at', 'author_id'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repo_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of commits per user\n",
    "sns.histplot(df['commits'], kde=True)\n",
    "plt.title('Distribution of Commits per User')\n",
    "plt.xlabel('Number of Commits')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Aggregate statistics for commits\n",
    "print(df['commits'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'commit_count' in descending order\n",
    "repo_summary_sorted = repo_summary.sort_values(by='commit_count', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(repo_summary_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 100 Repos by Commit Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'commit_count' in descending order and select the top 100\n",
    "top_100_repos = repo_summary.sort_values(by='commit_count', ascending=False).head(100)\n",
    "\n",
    "# Display the DataFrame with the top 100 repositories\n",
    "print(top_100_repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame into a CSV file\n",
    "repo_summary.to_csv('commits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open commit-centric and repo-centric dataframes to be joined together\n",
    "df_commits = pd.read_csv('commits.csv')\n",
    "df_repos = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_commits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform a left join with df_repos on the left\n",
    "df_merged = pd.merge(df_repos, df_commits, left_on='repo_full_name', right_on='repo_name', how='left', suffixes=('', '_drop'))\n",
    "\n",
    "# Drop duplicate or unwanted columns post-merge, especially those with '_drop' suffix\n",
    "df_merged = df_merged[[c for c in df_merged.columns if not c.endswith('_drop')]]\n",
    "\n",
    "# For repositories without attached commits, set 'commits' to 0 and 'commit_list' to []\n",
    "# Assuming 'commits' is a column you're interested in; replace or add as necessary based on your actual data structure\n",
    "df_merged['commit_count'] = df_merged['commit_count'].fillna(0)\n",
    "df_merged['commit_list'] = df_merged.apply(lambda row: [] if pd.isnull(row['commit_count']) else row['commit_list'], axis=1)\n",
    "\n",
    "# Display the first few rows of the merged DataFrame to verify the result\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of rows and columns in df_merged\n",
    "num_rows, num_columns = df_merged.shape\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove unneccessary columns, impute NaN values to [] or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the drop columns syntax\n",
    "df_merged.drop(['repo_id', 'repo_owner_id', 'repo_name'], axis=1, inplace=True)\n",
    "\n",
    "# Imputing missing commit values\n",
    "df_merged['commit_count'] = df_merged['commit_count'].fillna(0)\n",
    "\n",
    "# Placeholder for 'commit_list'; assuming you need to create or update it\n",
    "df_merged['commit_list'] = df_merged.apply(lambda row: [] if row['commit_count'] == 0 else row['commit_list'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the first few rows of the merged DataFrame to verify the result\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save File to CSV (repos , commit counts , commit_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('repos_commits.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe highly-committed repo's and their characteristics shared, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_by_commits = df_merged.sort_values(by='commit_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_by_commits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns_of_interest = ['repo_age', 'repo_stargazers_count', 'repo_forks_count', 'repo_open_issues', 'commit_count']\n",
    "df_sorted_by_commits[columns_of_interest].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Active Repositories by 10-day Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Initialize a list of the top k most starred and forked repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topKFrequent( input, k ):\n",
    "    input = Counter(input)\n",
    "    freq = input.most_common(k)\n",
    "\n",
    "    ret = []\n",
    "    for i in freq:\n",
    "        ret.append( i[0] )\n",
    "    \n",
    "    return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
